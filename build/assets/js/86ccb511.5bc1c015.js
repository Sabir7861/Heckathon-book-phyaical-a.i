"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[358],{6860(e,n,s){s.r(n),s.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>d,frontMatter:()=>l,metadata:()=>i,toc:()=>h});const i=JSON.parse('{"id":"foundations/lesson-01-what-is-physical-ai","title":"What is Physical AI?","description":"Discover what Physical AI is, why it matters, and how it differs from traditional software AI systems. Learn the fundamentals with hands-on examples.","source":"@site/docs/foundations/lesson-01-what-is-physical-ai.md","sourceDirName":"foundations","slug":"/foundations/lesson-01-what-is-physical-ai","permalink":"/docs/foundations/lesson-01-what-is-physical-ai","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"What is Physical AI?","description":"Discover what Physical AI is, why it matters, and how it differs from traditional software AI systems. Learn the fundamentals with hands-on examples.","keywords":["physical ai","robotics","artificial intelligence","embodied ai","cyber-physical systems"],"image":"/img/og/ch01-l01-what-is-physical-ai.png"},"sidebar":"bookSidebar","previous":{"title":"1. Foundations of Physical AI","permalink":"/docs/category/1-foundations-of-physical-ai"},"next":{"title":"Components of Physical AI Systems","permalink":"/docs/foundations/lesson-02-components-of-physical-ai"}}');var t=s(4848),r=s(8453);const l={sidebar_position:1,title:"What is Physical AI?",description:"Discover what Physical AI is, why it matters, and how it differs from traditional software AI systems. Learn the fundamentals with hands-on examples.",keywords:["physical ai","robotics","artificial intelligence","embodied ai","cyber-physical systems"],image:"/img/og/ch01-l01-what-is-physical-ai.png"},o="What is Physical AI?",a={},h=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Introduction",id:"introduction",level:2},{value:"What Makes AI &quot;Physical&quot;?",id:"what-makes-ai-physical",level:2},{value:"The Digital vs Physical Divide",id:"the-digital-vs-physical-divide",level:3},{value:"The Sense-Think-Act Cycle",id:"the-sense-think-act-cycle",level:3},{value:"Real-World Examples of Physical AI",id:"real-world-examples-of-physical-ai",level:2},{value:"Consumer Robotics",id:"consumer-robotics",level:3},{value:"Transportation",id:"transportation",level:3},{value:"Industrial Applications",id:"industrial-applications",level:3},{value:"Healthcare",id:"healthcare",level:3},{value:"Your First Physical AI Program",id:"your-first-physical-ai-program",level:2},{value:"Setting Up the Environment",id:"setting-up-the-environment",level:3},{value:"Understanding the Code",id:"understanding-the-code",level:3},{value:"Running the Code",id:"running-the-code",level:3},{value:"Key Concepts Recap",id:"key-concepts-recap",level:2},{value:"Physical AI Definition",id:"physical-ai-definition",level:3},{value:"The Four Pillars",id:"the-four-pillars",level:3},{value:"The Sense-Think-Act Cycle",id:"the-sense-think-act-cycle-1",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Summary",id:"summary",level:2},{value:"Key Takeaways",id:"key-takeaways",level:3},{value:"Checkpoint Quiz",id:"checkpoint-quiz",level:3},{value:"Exercises",id:"exercises",level:2},{value:'<span class="exercise-badge exercise-badge--basic">Basic</span> Exercise 1: Add Diagonal Movement',id:"basic-exercise-1-add-diagonal-movement",level:3},{value:'<span class="exercise-badge exercise-badge--intermediate">Intermediate</span> Exercise 2: Add Multiple Light Sources',id:"intermediate-exercise-2-add-multiple-light-sources",level:3},{value:"Further Reading",id:"further-reading",level:2},{value:"What&#39;s Next?",id:"whats-next",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components},{Details:s}=n;return s||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"what-is-physical-ai",children:"What is Physical AI?"})}),"\n",(0,t.jsx)("div",{className:"lesson-progress",children:(0,t.jsxs)(n.p,{children:["\ud83d\udcd6 ",(0,t.jsx)(n.strong,{children:"Chapter 1"})," \xb7 Lesson 1 of 3 \xb7 \u23f1\ufe0f 45 minutes"]})}),"\n",(0,t.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(n.p,{children:"By the end of this lesson, you will be able to:"}),"\n",(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Define Physical AI and explain how it differs from traditional software AI"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Identify real-world examples of Physical AI systems"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Understand the sense-think-act cycle that drives Physical AI"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Run your first Physical AI simulation in Python"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsx)(n.p,{children:"Before starting this lesson, you should have:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Basic Python programming knowledge (variables, functions, loops)"}),"\n",(0,t.jsx)(n.li,{children:"Python 3.8+ installed on your computer"}),"\n",(0,t.jsx)(n.li,{children:"A text editor or IDE (VS Code, PyCharm, or similar)"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsxs)(n.p,{children:["Imagine a world where machines don't just process data\u2014they reach out and touch it. Where artificial intelligence doesn't live behind a screen, but walks beside us, picks up objects, navigates our cities, and interacts with the physical environment just as we do. This is the world of ",(0,t.jsx)(n.strong,{children:"Physical AI"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"Physical AI represents a fundamental shift in how we think about intelligent systems. Unlike chatbots or recommendation engines that exist purely in the digital realm, Physical AI systems have bodies. They have sensors that perceive the world, processors that make decisions, and actuators that take action. From the robot vacuum cleaning your floor to autonomous vehicles navigating city streets, Physical AI is already transforming how machines interact with our world."}),"\n",(0,t.jsx)(n.p,{children:"In this lesson, we'll explore what makes Physical AI unique, why it matters, and how you can start building your own intelligent physical systems. By the end, you'll have written your first Physical AI program\u2014a simple agent that perceives its environment and responds to it."}),"\n",(0,t.jsx)(n.admonition,{title:"Why This Matters",type:"tip",children:(0,t.jsx)(n.p,{children:"Physical AI is one of the fastest-growing fields in technology. By 2030, the global robotics market is expected to exceed $200 billion. Understanding Physical AI opens doors to careers in robotics, autonomous vehicles, smart manufacturing, healthcare automation, and countless other industries."})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"what-makes-ai-physical",children:'What Makes AI "Physical"?'}),"\n",(0,t.jsx)(n.h3,{id:"the-digital-vs-physical-divide",children:"The Digital vs Physical Divide"}),"\n",(0,t.jsx)(n.p,{children:"Traditional AI systems\u2014like the ones that recommend movies, translate languages, or generate images\u2014operate entirely in the digital world. They take digital inputs (text, images, data) and produce digital outputs (predictions, text, more images)."}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Physical AI is different."})," It bridges the gap between the digital and physical worlds:"]}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Aspect"}),(0,t.jsx)(n.th,{children:"Traditional AI"}),(0,t.jsx)(n.th,{children:"Physical AI"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Input"})}),(0,t.jsx)(n.td,{children:"Digital data (text, images, databases)"}),(0,t.jsx)(n.td,{children:"Sensor data from the real world (cameras, LIDAR, touch sensors)"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Processing"})}),(0,t.jsx)(n.td,{children:"Cloud servers or local computers"}),(0,t.jsx)(n.td,{children:"Often embedded systems with real-time constraints"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Output"})}),(0,t.jsx)(n.td,{children:"Digital results (predictions, text, images)"}),(0,t.jsx)(n.td,{children:"Physical actions (movement, manipulation, sound)"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Environment"})}),(0,t.jsx)(n.td,{children:"Controlled, predictable"}),(0,t.jsx)(n.td,{children:"Dynamic, unpredictable, noisy"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Consequences"})}),(0,t.jsx)(n.td,{children:"Virtual (can be undone)"}),(0,t.jsx)(n.td,{children:"Real (physical impact on the world)"})]})]})]}),"\n",(0,t.jsx)(n.h3,{id:"the-sense-think-act-cycle",children:"The Sense-Think-Act Cycle"}),"\n",(0,t.jsxs)(n.p,{children:["Every Physical AI system operates on a fundamental loop called the ",(0,t.jsx)(n.strong,{children:"Sense-Think-Act cycle"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  SENSE-THINK-ACT CYCLE                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                         \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502    \u2502  SENSE  \u2502 \u2500\u2500\u2500\u25ba \u2502  THINK  \u2502 \u2500\u2500\u2500\u25ba \u2502   ACT   \u2502       \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n\u2502         \u25b2                                   \u2502          \u2502\n\u2502         \u2502                                   \u2502          \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 FEEDBACK \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502                                                         \u2502\n\u2502  \u2022 Cameras        \u2022 Process data      \u2022 Motors         \u2502\n\u2502  \u2022 Microphones    \u2022 Make decisions    \u2022 Speakers       \u2502\n\u2502  \u2022 Touch sensors  \u2022 Plan actions      \u2022 Displays       \u2502\n\u2502  \u2022 LIDAR/Radar    \u2022 Learn patterns    \u2022 Grippers       \u2502\n\u2502                                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Sense"}),": The system gathers information about its environment through sensors (cameras, microphones, touch sensors, GPS, etc.)"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Think"}),": The system processes this information, makes decisions, and plans actions based on its goals and understanding of the world"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Act"}),": The system executes physical actions through actuators (motors, speakers, displays, robotic arms, etc.)"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Feedback"}),": The results of actions change the environment, which the system senses again, completing the loop"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"This cycle runs continuously\u2014sometimes hundreds of times per second\u2014allowing Physical AI systems to respond dynamically to their environment."}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"real-world-examples-of-physical-ai",children:"Real-World Examples of Physical AI"}),"\n",(0,t.jsx)(n.p,{children:"Physical AI is already all around us. Let's look at some examples across different domains:"}),"\n",(0,t.jsx)(n.h3,{id:"consumer-robotics",children:"Consumer Robotics"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Robot Vacuums (e.g., Roomba, Roborock)"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sense"}),": Cameras, bump sensors, cliff sensors, LIDAR"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Think"}),": Mapping algorithms, path planning, obstacle avoidance"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Act"}),": Wheel motors, vacuum motor, brush motors"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Smart Speakers (e.g., Amazon Echo, Google Home)"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sense"}),": Microphone arrays for voice detection"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Think"}),": Speech recognition, natural language processing"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Act"}),": Speaker output, smart home device control"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"transportation",children:"Transportation"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Autonomous Vehicles (e.g., Waymo, Tesla Autopilot)"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sense"}),": Cameras, LIDAR, radar, ultrasonic sensors, GPS"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Think"}),": Object detection, path planning, behavior prediction"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Act"}),": Steering, acceleration, braking"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Delivery Drones (e.g., Amazon Prime Air, Wing)"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sense"}),": Cameras, GPS, altimeters, obstacle sensors"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Think"}),": Navigation, obstacle avoidance, delivery planning"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Act"}),": Rotor motors, package release mechanism"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"industrial-applications",children:"Industrial Applications"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Manufacturing Robots (e.g., robotic arms in factories)"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sense"}),": Vision systems, force/torque sensors, position encoders"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Think"}),": Motion planning, quality inspection, coordination"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Act"}),": Multi-axis robotic arm movements, grippers"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Warehouse Automation (e.g., Amazon fulfillment centers)"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sense"}),": Barcode scanners, cameras, proximity sensors"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Think"}),": Inventory management, route optimization"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Act"}),": Mobile robot navigation, shelf lifting"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"healthcare",children:"Healthcare"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Surgical Robots (e.g., da Vinci Surgical System)"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sense"}),": High-definition cameras, force feedback sensors"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Think"}),": Motion scaling, tremor filtering, procedure planning"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Act"}),": Precise instrument control, tissue manipulation"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Rehabilitation Exoskeletons"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sense"}),": EMG sensors, accelerometers, pressure sensors"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Think"}),": Intent detection, gait analysis, adaptive support"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Act"}),": Powered joint assistance"]}),"\n"]}),"\n",(0,t.jsx)(n.admonition,{title:"Key Insight",type:"info",children:(0,t.jsx)(n.p,{children:"Notice how every example follows the Sense-Think-Act pattern. This universal framework is the foundation of all Physical AI systems, regardless of their specific application."})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"your-first-physical-ai-program",children:"Your First Physical AI Program"}),"\n",(0,t.jsx)(n.p,{children:"Let's write your first Physical AI program. We'll create a simple simulated agent that:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Senses"})," its environment (light levels)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Thinks"})," about what to do (decides direction)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Acts"})," on its decision (moves toward light)"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["This is a fundamental behavior called ",(0,t.jsx)(n.strong,{children:"phototaxis"}),"\u2014movement toward or away from light\u2014seen in everything from bacteria to robots."]}),"\n",(0,t.jsx)(n.h3,{id:"setting-up-the-environment",children:"Setting Up the Environment"}),"\n",(0,t.jsx)(n.p,{children:"First, let's create a simple 2D world with a light source:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'"""\nPhysical AI - Lesson 1.1: Light-Seeking Agent\nA simple demonstration of the Sense-Think-Act cycle.\n\nThis simulation creates a virtual robot that seeks light sources,\ndemonstrating the fundamental principles of Physical AI.\n"""\n\nimport math\nimport random\n\n\nclass Environment:\n    """\n    A simple 2D environment with a light source.\n\n    The environment is a 100x100 grid where light intensity\n    decreases with distance from the light source.\n    """\n\n    def __init__(self, width=100, height=100):\n        self.width = width\n        self.height = height\n        # Place light source at a random position\n        self.light_x = random.randint(20, width - 20)\n        self.light_y = random.randint(20, height - 20)\n        print(f"Light source placed at ({self.light_x}, {self.light_y})")\n\n    def get_light_intensity(self, x, y):\n        """\n        Calculate light intensity at a given position.\n\n        Light intensity follows inverse square law:\n        intensity = 1 / (1 + distance^2 / 1000)\n\n        Returns a value between 0 (dark) and 1 (brightest).\n        """\n        distance = math.sqrt((x - self.light_x)**2 + (y - self.light_y)**2)\n        intensity = 1 / (1 + (distance ** 2) / 1000)\n        return intensity\n\n    def is_within_bounds(self, x, y):\n        """Check if a position is within the environment bounds."""\n        return 0 <= x < self.width and 0 <= y < self.height\n\n\nclass LightSeekingAgent:\n    """\n    A simple Physical AI agent that seeks light sources.\n\n    This agent demonstrates the Sense-Think-Act cycle:\n    - SENSE: Measure light intensity at current position\n    - THINK: Decide which direction has more light\n    - ACT: Move toward the brighter area\n    """\n\n    def __init__(self, x, y, environment):\n        self.x = x\n        self.y = y\n        self.environment = environment\n        self.history = [(x, y)]  # Track movement history\n\n    def sense(self):\n        """\n        SENSE: Gather information about the environment.\n\n        Our simple robot has light sensors pointing in 4 directions.\n        Each sensor measures light intensity slightly ahead in that direction.\n        """\n        sensor_distance = 5  # How far ahead each sensor looks\n\n        readings = {\n            \'north\': self.environment.get_light_intensity(self.x, self.y - sensor_distance),\n            \'south\': self.environment.get_light_intensity(self.x, self.y + sensor_distance),\n            \'east\': self.environment.get_light_intensity(self.x + sensor_distance, self.y),\n            \'west\': self.environment.get_light_intensity(self.x - sensor_distance, self.y),\n        }\n\n        return readings\n\n    def think(self, sensor_readings):\n        """\n        THINK: Process sensor data and decide on an action.\n\n        Strategy: Move toward the direction with highest light intensity.\n        This is a simple "greedy" algorithm - always chase the brightest spot.\n        """\n        # Find the direction with maximum light\n        best_direction = max(sensor_readings, key=sensor_readings.get)\n\n        # Map direction to movement delta\n        movement_map = {\n            \'north\': (0, -1),\n            \'south\': (0, 1),\n            \'east\': (1, 0),\n            \'west\': (-1, 0),\n        }\n\n        return movement_map[best_direction], best_direction\n\n    def act(self, movement):\n        """\n        ACT: Execute the decided movement.\n\n        Move the robot by the specified delta, if within bounds.\n        """\n        dx, dy = movement\n        new_x = self.x + dx\n        new_y = self.y + dy\n\n        # Only move if within environment bounds\n        if self.environment.is_within_bounds(new_x, new_y):\n            self.x = new_x\n            self.y = new_y\n            self.history.append((self.x, self.y))\n            return True\n        return False\n\n    def run_cycle(self):\n        """\n        Execute one complete Sense-Think-Act cycle.\n\n        Returns information about what happened in this cycle.\n        """\n        # SENSE\n        readings = self.sense()\n        current_light = self.environment.get_light_intensity(self.x, self.y)\n\n        # THINK\n        movement, direction = self.think(readings)\n\n        # ACT\n        moved = self.act(movement)\n\n        return {\n            \'position\': (self.x, self.y),\n            \'light_level\': current_light,\n            \'direction\': direction,\n            \'moved\': moved\n        }\n\n    def distance_to_light(self):\n        """Calculate current distance to the light source."""\n        return math.sqrt(\n            (self.x - self.environment.light_x)**2 +\n            (self.y - self.environment.light_y)**2\n        )\n\n\ndef run_simulation(num_steps=50):\n    """\n    Run the light-seeking simulation.\n\n    Creates an environment with a light source and an agent,\n    then runs the Sense-Think-Act cycle for the specified number of steps.\n    """\n    print("=" * 60)\n    print("PHYSICAL AI SIMULATION: Light-Seeking Agent")\n    print("=" * 60)\n    print()\n\n    # Create environment\n    env = Environment(width=100, height=100)\n\n    # Create agent at a random starting position\n    start_x = random.randint(10, 90)\n    start_y = random.randint(10, 90)\n    agent = LightSeekingAgent(start_x, start_y, env)\n\n    print(f"Agent starting at ({start_x}, {start_y})")\n    print(f"Initial distance to light: {agent.distance_to_light():.2f}")\n    print()\n    print("Running Sense-Think-Act cycles...")\n    print("-" * 60)\n\n    # Run simulation\n    for step in range(num_steps):\n        result = agent.run_cycle()\n\n        # Print progress every 10 steps\n        if step % 10 == 0 or step == num_steps - 1:\n            print(f"Step {step:3d}: Position {result[\'position\']}, "\n                  f"Light: {result[\'light_level\']:.4f}, "\n                  f"Moving: {result[\'direction\']}")\n\n    print("-" * 60)\n    print()\n    print("SIMULATION COMPLETE")\n    print(f"Final position: ({agent.x}, {agent.y})")\n    print(f"Final distance to light: {agent.distance_to_light():.2f}")\n    print(f"Total steps taken: {len(agent.history) - 1}")\n\n    # Check if agent found the light\n    if agent.distance_to_light() < 5:\n        print("SUCCESS! Agent reached the light source!")\n    else:\n        print("Agent is still approaching the light source.")\n\n    return agent\n\n\n# Run the simulation\nif __name__ == "__main__":\n    agent = run_simulation(num_steps=100)\n'})}),"\n",(0,t.jsx)(n.h3,{id:"understanding-the-code",children:"Understanding the Code"}),"\n",(0,t.jsx)(n.p,{children:"Let's break down what each part does:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"The Environment Class"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Creates a 100x100 virtual world"}),"\n",(0,t.jsx)(n.li,{children:"Places a light source at a random position"}),"\n",(0,t.jsx)(n.li,{children:"Calculates light intensity at any point (brighter near the source)"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"The LightSeekingAgent Class"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Implements the Sense-Think-Act cycle"}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"sense()"}),": Reads light levels in four directions"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"think()"}),": Chooses the brightest direction"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"act()"}),": Moves one step in the chosen direction"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"The Simulation"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Creates the world and places the agent"}),"\n",(0,t.jsx)(n.li,{children:"Runs 100 cycles of Sense-Think-Act"}),"\n",(0,t.jsx)(n.li,{children:"Reports the agent's progress toward the light"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"running-the-code",children:"Running the Code"}),"\n",(0,t.jsxs)(n.p,{children:["Save the code as ",(0,t.jsx)(n.code,{children:"light_seeker.py"})," and run it:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"python light_seeker.py\n"})}),"\n",(0,t.jsx)(n.p,{children:"You should see output like this:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"============================================================\nPHYSICAL AI SIMULATION: Light-Seeking Agent\n============================================================\n\nLight source placed at (67, 43)\nAgent starting at (23, 78)\nInitial distance to light: 55.22\n\nRunning Sense-Think-Act cycles...\n------------------------------------------------------------\nStep   0: Position (24, 78), Light: 0.2451, Moving: east\nStep  10: Position (34, 68), Light: 0.3892, Moving: east\nStep  20: Position (44, 58), Light: 0.5234, Moving: east\nStep  30: Position (54, 48), Light: 0.6891, Moving: east\nStep  40: Position (64, 44), Light: 0.9012, Moving: east\nStep  50: Position (67, 43), Light: 1.0000, Moving: north\n...\n------------------------------------------------------------\n\nSIMULATION COMPLETE\nFinal position: (67, 43)\nFinal distance to light: 0.00\nTotal steps taken: 52\nSUCCESS! Agent reached the light source!\n"})}),"\n",(0,t.jsx)(n.admonition,{title:"Common Pitfall",type:"warning",children:(0,t.jsx)(n.p,{children:"If your agent gets stuck or moves erratically, check that your sensor readings are being compared correctly. A common bug is comparing intensity values as strings instead of numbers."})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"key-concepts-recap",children:"Key Concepts Recap"}),"\n",(0,t.jsx)(n.p,{children:"Let's summarize the key concepts we've covered:"}),"\n",(0,t.jsx)(n.h3,{id:"physical-ai-definition",children:"Physical AI Definition"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Physical AI"})," refers to artificial intelligence systems that:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Interact with the physical world through sensors and actuators"}),"\n",(0,t.jsx)(n.li,{children:"Operate in real-time with real-world consequences"}),"\n",(0,t.jsx)(n.li,{children:"Must handle uncertainty, noise, and dynamic environments"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"the-four-pillars",children:"The Four Pillars"}),"\n",(0,t.jsx)(n.p,{children:"Physical AI systems are built on four fundamental pillars:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Perception"})," - Sensing and understanding the environment"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Reasoning"})," - Processing information and making decisions"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Actuation"})," - Taking physical actions in the world"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Learning"})," - Improving performance over time"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"We'll explore each of these in depth throughout this book."}),"\n",(0,t.jsx)(n.h3,{id:"the-sense-think-act-cycle-1",children:"The Sense-Think-Act Cycle"}),"\n",(0,t.jsx)(n.p,{children:"Every Physical AI system follows this fundamental loop:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sense"}),": Gather environmental data through sensors"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Think"}),": Process data, make decisions, plan actions"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Act"}),": Execute physical actions through actuators"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Repeat"}),": The cycle continues, with each action changing what's sensed next"]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Issue"}),(0,t.jsx)(n.th,{children:"Possible Cause"}),(0,t.jsx)(n.th,{children:"Solution"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Agent doesn't move"}),(0,t.jsx)(n.td,{children:"Movement delta is (0,0)"}),(0,t.jsx)(n.td,{children:"Check that sensor readings differ in each direction"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Agent moves away from light"}),(0,t.jsx)(n.td,{children:"Max/min confusion in think()"}),(0,t.jsxs)(n.td,{children:["Verify you're using ",(0,t.jsx)(n.code,{children:"max()"})," to find brightest direction"]})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Agent gets stuck at edge"}),(0,t.jsx)(n.td,{children:"Bounds checking blocks all moves"}),(0,t.jsx)(n.td,{children:"Start agent away from edges; add diagonal movement"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Light intensity always 0"}),(0,t.jsx)(n.td,{children:"Division error in calculation"}),(0,t.jsx)(n.td,{children:"Check the intensity formula denominator"})]})]})]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(n.h3,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["\u2705 ",(0,t.jsx)(n.strong,{children:"Physical AI"})," bridges the digital and physical worlds, enabling machines to perceive, reason about, and act in real environments"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["\u2705 The ",(0,t.jsx)(n.strong,{children:"Sense-Think-Act cycle"})," is the fundamental operating loop of all Physical AI systems"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"\u2705 Physical AI is already transforming industries from transportation to healthcare to manufacturing"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"\u2705 Even simple agents can exhibit intelligent behavior by following the Sense-Think-Act pattern"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"checkpoint-quiz",children:"Checkpoint Quiz"}),"\n",(0,t.jsxs)("div",{className:"checkpoint-quiz",children:[(0,t.jsx)(n.p,{children:"Test your understanding:"}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"What is the main difference between traditional AI and Physical AI?"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Name the three stages of the Sense-Think-Act cycle and give an example of each for a robot vacuum."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:'Why is the "feedback" component important in the Sense-Think-Act cycle?'}),"\n"]}),"\n"]}),(0,t.jsxs)(s,{children:[(0,t.jsx)("summary",{children:"View Answers"}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Traditional AI"})," operates entirely in the digital world (processing data, generating text/images), while ",(0,t.jsx)(n.strong,{children:"Physical AI"})," interacts with the real world through sensors (input) and actuators (output), dealing with physical consequences and real-time constraints."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"For a robot vacuum:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sense"}),": Bump sensors detect obstacles, cliff sensors detect stairs, cameras map the room"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Think"}),": Path planning algorithms decide the cleaning route, obstacle avoidance logic"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Act"}),": Wheel motors move the robot, vacuum motor cleans, brush motors agitate dirt"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Feedback"})," is crucial because actions change the environment. Without sensing these changes, the system couldn't respond to the results of its actions. For example, after a robot moves, it needs to sense its new position to plan the next move. This creates a continuous loop of adaptation."]}),"\n"]}),"\n"]})]})]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,t.jsxs)(n.h3,{id:"basic-exercise-1-add-diagonal-movement",children:[(0,t.jsx)("span",{className:"exercise-badge exercise-badge--basic",children:"Basic"})," Exercise 1: Add Diagonal Movement"]}),"\n",(0,t.jsxs)(n.p,{children:["Modify the ",(0,t.jsx)(n.code,{children:"LightSeekingAgent"})," to support 8 directions instead of 4 (add northeast, northwest, southeast, southwest)."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Hints:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Add four more entries to the sensor readings dictionary"}),"\n",(0,t.jsxs)(n.li,{children:["Update the movement_map to include diagonal movements like ",(0,t.jsx)(n.code,{children:"(1, -1)"})," for northeast"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Expected Outcome:"})," The agent should reach the light source faster because it can take more direct paths."]}),"\n",(0,t.jsxs)(s,{children:[(0,t.jsx)("summary",{children:"View Solution"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"def sense(self):\n    \"\"\"\n    SENSE: Gather information about the environment.\n    Updated to include 8 directions for diagonal movement.\n    \"\"\"\n    sensor_distance = 5\n\n    readings = {\n        'north': self.environment.get_light_intensity(self.x, self.y - sensor_distance),\n        'south': self.environment.get_light_intensity(self.x, self.y + sensor_distance),\n        'east': self.environment.get_light_intensity(self.x + sensor_distance, self.y),\n        'west': self.environment.get_light_intensity(self.x - sensor_distance, self.y),\n        # New diagonal directions\n        'northeast': self.environment.get_light_intensity(self.x + sensor_distance, self.y - sensor_distance),\n        'northwest': self.environment.get_light_intensity(self.x - sensor_distance, self.y - sensor_distance),\n        'southeast': self.environment.get_light_intensity(self.x + sensor_distance, self.y + sensor_distance),\n        'southwest': self.environment.get_light_intensity(self.x - sensor_distance, self.y + sensor_distance),\n    }\n\n    return readings\n\ndef think(self, sensor_readings):\n    \"\"\"\n    THINK: Process sensor data and decide on an action.\n    Updated to handle 8 directions.\n    \"\"\"\n    best_direction = max(sensor_readings, key=sensor_readings.get)\n\n    movement_map = {\n        'north': (0, -1),\n        'south': (0, 1),\n        'east': (1, 0),\n        'west': (-1, 0),\n        # New diagonal movements\n        'northeast': (1, -1),\n        'northwest': (-1, -1),\n        'southeast': (1, 1),\n        'southwest': (-1, 1),\n    }\n\n    return movement_map[best_direction], best_direction\n"})})]}),"\n",(0,t.jsxs)(n.h3,{id:"intermediate-exercise-2-add-multiple-light-sources",children:[(0,t.jsx)("span",{className:"exercise-badge exercise-badge--intermediate",children:"Intermediate"})," Exercise 2: Add Multiple Light Sources"]}),"\n",(0,t.jsxs)(n.p,{children:["Modify the ",(0,t.jsx)(n.code,{children:"Environment"})," class to support multiple light sources. The light intensity at any point should be the sum of intensities from all sources."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Hints:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Change ",(0,t.jsx)(n.code,{children:"light_x"})," and ",(0,t.jsx)(n.code,{children:"light_y"})," to a list of positions"]}),"\n",(0,t.jsxs)(n.li,{children:["Update ",(0,t.jsx)(n.code,{children:"get_light_intensity()"})," to sum contributions from all lights"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Expected Outcome:"})," The agent should navigate toward the brightest overall area, which may be between multiple light sources."]}),"\n",(0,t.jsxs)(s,{children:[(0,t.jsx)("summary",{children:"View Solution"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'class MultiLightEnvironment:\n    """\n    A 2D environment with multiple light sources.\n    """\n\n    def __init__(self, width=100, height=100, num_lights=3):\n        self.width = width\n        self.height = height\n\n        # Create multiple light sources at random positions\n        self.lights = []\n        for i in range(num_lights):\n            light_x = random.randint(20, width - 20)\n            light_y = random.randint(20, height - 20)\n            self.lights.append((light_x, light_y))\n            print(f"Light source {i+1} placed at ({light_x}, {light_y})")\n\n    def get_light_intensity(self, x, y):\n        """\n        Calculate combined light intensity from all sources.\n\n        The total intensity is the sum of individual intensities,\n        capped at 1.0 for normalization.\n        """\n        total_intensity = 0\n\n        for light_x, light_y in self.lights:\n            distance = math.sqrt((x - light_x)**2 + (y - light_y)**2)\n            intensity = 1 / (1 + (distance ** 2) / 1000)\n            total_intensity += intensity\n\n        # Cap at 1.0 to normalize\n        return min(total_intensity, 1.0)\n\n    def is_within_bounds(self, x, y):\n        """Check if a position is within the environment bounds."""\n        return 0 <= x < self.width and 0 <= y < self.height\n\n    def distance_to_nearest_light(self, x, y):\n        """Calculate distance to the nearest light source."""\n        min_distance = float(\'inf\')\n        for light_x, light_y in self.lights:\n            distance = math.sqrt((x - light_x)**2 + (y - light_y)**2)\n            min_distance = min(min_distance, distance)\n        return min_distance\n\n\n# Usage:\n# env = MultiLightEnvironment(width=100, height=100, num_lights=3)\n# agent = LightSeekingAgent(start_x, start_y, env)\n'})})]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\ud83d\udcc4 ",(0,t.jsx)(n.a,{href:"https://cs.stanford.edu/groups/manips/teaching/cs223a/",children:"Introduction to Robotics (Stanford CS223A)"})," - Academic foundation for robotics concepts"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udcc4 ",(0,t.jsx)(n.a,{href:"https://docs.ros.org/en/humble/Tutorials.html",children:"ROS (Robot Operating System) Tutorials"})," - Industry-standard robotics framework"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udcf9 ",(0,t.jsx)(n.a,{href:"https://ocw.mit.edu/courses/mechanical-engineering/2-12-introduction-to-robotics-fall-2005/",children:"MIT OpenCourseWare: Introduction to Robotics"})," - Video lectures on robotics fundamentals"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udcc4 ",(0,t.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Braitenberg_vehicle",children:"Braitenberg Vehicles"})," - The theoretical basis for our light-seeking agent"]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"whats-next",children:"What's Next?"}),"\n",(0,t.jsxs)(n.p,{children:["In the next lesson, ",(0,t.jsx)(n.a,{href:"/docs/01-foundations/lesson-02-components-of-physical-ai",children:"Components of Physical AI Systems"}),", you'll dive deeper into the four pillars of Physical AI: perception, reasoning, actuation, and learning. You'll learn about the specific technologies and techniques used in each area and how they work together to create intelligent physical systems."]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Estimated completion time: 45 minutes"})})]})}function d(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453(e,n,s){s.d(n,{R:()=>l,x:()=>o});var i=s(6540);const t={},r=i.createContext(t);function l(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);
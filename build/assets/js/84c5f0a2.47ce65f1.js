"use strict";(self.webpackChunkphysical_ai_book=self.webpackChunkphysical_ai_book||[]).push([[352],{4680(n,e,i){i.r(e),i.d(e,{assets:()=>a,contentTitle:()=>c,default:()=>f,frontMatter:()=>s,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"learning/lesson-02-reinforcement-learning-intro","title":"Reinforcement Learning Introduction","description":"Core concepts of reinforcement learning for robotics.","source":"@site/docs/learning/lesson-02-reinforcement-learning-intro.md","sourceDirName":"learning","slug":"/learning/lesson-02-reinforcement-learning-intro","permalink":"/learning/lesson-02-reinforcement-learning-intro","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Reinforcement Learning Introduction","description":"Core concepts of reinforcement learning for robotics."},"sidebar":"bookSidebar","previous":{"title":"Machine Learning for Robotics","permalink":"/learning/lesson-01-machine-learning-for-robotics"},"next":{"title":"Training Your Physical AI","permalink":"/learning/lesson-03-training-your-physical-ai"}}');var o=i(4848),t=i(8453);const s={sidebar_position:2,title:"Reinforcement Learning Introduction",description:"Core concepts of reinforcement learning for robotics."},c="Reinforcement Learning Introduction",a={},l=[{value:"Learning Objectives",id:"learning-objectives",level:2}];function d(n){const e={em:"em",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,t.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"reinforcement-learning-introduction",children:"Reinforcement Learning Introduction"})}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.em,{children:"Coming soon - This lesson is under development."})}),"\n",(0,o.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Understand agents, environments, and rewards"}),"\n",(0,o.jsx)(e.li,{children:"Learn the exploration-exploitation tradeoff"}),"\n",(0,o.jsx)(e.li,{children:"Implement basic RL algorithms"}),"\n"]})]})}function f(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453(n,e,i){i.d(e,{R:()=>s,x:()=>c});var r=i(6540);const o={},t=r.createContext(o);function s(n){const e=r.useContext(t);return r.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function c(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),r.createElement(t.Provider,{value:e},n.children)}}}]);
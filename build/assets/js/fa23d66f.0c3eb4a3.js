"use strict";(self.webpackChunkphysical_ai_book=self.webpackChunkphysical_ai_book||[]).push([[367],{7765(e,n,s){s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"foundations/lesson-02-components-of-physical-ai","title":"Components of Physical AI Systems","description":"Deep dive into the four pillars of Physical AI: perception, reasoning, actuation, and learning. Understand how these components work together.","source":"@site/docs/foundations/lesson-02-components-of-physical-ai.md","sourceDirName":"foundations","slug":"/foundations/lesson-02-components-of-physical-ai","permalink":"/foundations/lesson-02-components-of-physical-ai","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Components of Physical AI Systems","description":"Deep dive into the four pillars of Physical AI: perception, reasoning, actuation, and learning. Understand how these components work together.","keywords":["perception","reasoning","actuation","learning","sensors","actuators","robotics components"],"image":"/img/og/ch01-l02-components.png"},"sidebar":"bookSidebar","previous":{"title":"What is Physical AI?","permalink":"/foundations/lesson-01-what-is-physical-ai"},"next":{"title":"Your First Physical AI System","permalink":"/foundations/lesson-03-your-first-physical-ai-system"}}');var i=s(4848),r=s(8453);const a={sidebar_position:2,title:"Components of Physical AI Systems",description:"Deep dive into the four pillars of Physical AI: perception, reasoning, actuation, and learning. Understand how these components work together.",keywords:["perception","reasoning","actuation","learning","sensors","actuators","robotics components"],image:"/img/og/ch01-l02-components.png"},o="Components of Physical AI Systems",l={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Introduction",id:"introduction",level:2},{value:"The Four Pillars Framework",id:"the-four-pillars-framework",level:2},{value:"Pillar 1: Perception",id:"pillar-1-perception",level:2},{value:"Common Sensor Types",id:"common-sensor-types",level:3},{value:"Camera Systems",id:"camera-systems",level:3},{value:"Distance Sensors",id:"distance-sensors",level:3},{value:"Sensor Fusion",id:"sensor-fusion",level:3},{value:"Pillar 2: Reasoning",id:"pillar-2-reasoning",level:2},{value:"Levels of Reasoning",id:"levels-of-reasoning",level:3},{value:"State Machine Implementation",id:"state-machine-implementation",level:3},{value:"Pillar 3: Actuation",id:"pillar-3-actuation",level:2},{value:"Common Actuator Types",id:"common-actuator-types",level:3},{value:"Motor Control Example",id:"motor-control-example",level:3},{value:"Pillar 4: Learning",id:"pillar-4-learning",level:2},{value:"Types of Learning in Physical AI",id:"types-of-learning-in-physical-ai",level:3},{value:"Simple Learning Example",id:"simple-learning-example",level:3},{value:"How the Pillars Work Together",id:"how-the-pillars-work-together",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Summary",id:"summary",level:2},{value:"Key Takeaways",id:"key-takeaways",level:3},{value:"Checkpoint Quiz",id:"checkpoint-quiz",level:3},{value:"Exercises",id:"exercises",level:2},{value:'<span class="exercise-badge exercise-badge--basic">Basic</span> Exercise 1: Sensor Comparison',id:"basic-exercise-1-sensor-comparison",level:3},{value:'<span class="exercise-badge exercise-badge--intermediate">Intermediate</span> Exercise 2: State Machine Design',id:"intermediate-exercise-2-state-machine-design",level:3},{value:"Further Reading",id:"further-reading",level:2},{value:"What&#39;s Next?",id:"whats-next",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components},{Details:s}=n;return s||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"components-of-physical-ai-systems",children:"Components of Physical AI Systems"})}),"\n",(0,i.jsx)("div",{className:"lesson-progress",children:(0,i.jsxs)(n.p,{children:["\ud83d\udcd6 ",(0,i.jsx)(n.strong,{children:"Chapter 1"})," \xb7 Lesson 2 of 3 \xb7 \u23f1\ufe0f 60 minutes"]})}),"\n",(0,i.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(n.p,{children:"By the end of this lesson, you will be able to:"}),"\n",(0,i.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Explain the four pillars of Physical AI (perception, reasoning, actuation, learning)"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Identify common sensors and their applications"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Understand different types of actuators and when to use them"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Describe how the four pillars work together in a complete system"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsx)(n.p,{children:"Before starting this lesson, you should have:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Completed ",(0,i.jsx)(n.a,{href:"/docs/01-foundations/lesson-01-what-is-physical-ai",children:"Lesson 1.1: What is Physical AI?"})]}),"\n",(0,i.jsx)(n.li,{children:"Basic understanding of the Sense-Think-Act cycle"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,i.jsx)(n.p,{children:"In our previous lesson, we learned that Physical AI systems interact with the real world through sensors and actuators. But what exactly are these components? How do they work? And how do they combine to create intelligent behavior?"}),"\n",(0,i.jsxs)(n.p,{children:["This lesson takes a deep dive into the ",(0,i.jsx)(n.strong,{children:"four pillars"})," that support every Physical AI system. Think of these as the essential building blocks\u2014just as a house needs a foundation, walls, roof, and utilities, a Physical AI system needs perception, reasoning, actuation, and learning. Understanding each pillar will help you design better systems and troubleshoot problems when things go wrong."]}),"\n",(0,i.jsx)(n.p,{children:"By the end of this lesson, you'll have a comprehensive mental model of how Physical AI systems are constructed, from individual components to integrated architectures."}),"\n",(0,i.jsx)(n.admonition,{title:"Why This Matters",type:"tip",children:(0,i.jsx)(n.p,{children:"Whether you're building a simple robot or working on autonomous vehicles, these four pillars remain constant. Mastering them gives you a framework for understanding any Physical AI system you encounter."})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"the-four-pillars-framework",children:"The Four Pillars Framework"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    PHYSICAL AI ARCHITECTURE                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                     \u2502\n\u2502                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                              \u2502\n\u2502                        \u2502   LEARNING  \u2502                              \u2502\n\u2502                        \u2502  (Improve)  \u2502                              \u2502\n\u2502                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                              \u2502\n\u2502                               \u2502                                     \u2502\n\u2502                               \u25bc                                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502   \u2502 PERCEPTION  \u2502 \u2500\u2500\u2500\u25ba \u2502  REASONING  \u2502 \u2500\u2500\u2500\u25ba \u2502  ACTUATION  \u2502        \u2502\n\u2502   \u2502  (Sense)    \u2502      \u2502   (Think)   \u2502      \u2502    (Act)    \u2502        \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2502         \u25b2                                          \u2502               \u2502\n\u2502         \u2502                                          \u2502               \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 ENVIRONMENT \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2502                                                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,i.jsx)(n.p,{children:"Let's explore each pillar in detail."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"pillar-1-perception",children:"Pillar 1: Perception"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Perception"}),' is how a Physical AI system gathers information about its environment. It answers the question: "What\'s happening around me?"']}),"\n",(0,i.jsx)(n.h3,{id:"common-sensor-types",children:"Common Sensor Types"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Sensor Type"}),(0,i.jsx)(n.th,{children:"What It Measures"}),(0,i.jsx)(n.th,{children:"Common Uses"}),(0,i.jsx)(n.th,{children:"Range/Precision"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Camera"})}),(0,i.jsx)(n.td,{children:"Visual imagery"}),(0,i.jsx)(n.td,{children:"Object detection, navigation"}),(0,i.jsx)(n.td,{children:"cm to km"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"LIDAR"})}),(0,i.jsx)(n.td,{children:"Distance via laser"}),(0,i.jsx)(n.td,{children:"3D mapping, obstacle detection"}),(0,i.jsx)(n.td,{children:"cm to 200m"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Ultrasonic"})}),(0,i.jsx)(n.td,{children:"Distance via sound"}),(0,i.jsx)(n.td,{children:"Proximity sensing"}),(0,i.jsx)(n.td,{children:"2cm to 4m"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"IMU"})}),(0,i.jsx)(n.td,{children:"Acceleration, rotation"}),(0,i.jsx)(n.td,{children:"Orientation, motion tracking"}),(0,i.jsx)(n.td,{children:"High precision"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"GPS"})}),(0,i.jsx)(n.td,{children:"Global position"}),(0,i.jsx)(n.td,{children:"Outdoor navigation"}),(0,i.jsx)(n.td,{children:"1-10m accuracy"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Infrared"})}),(0,i.jsx)(n.td,{children:"Heat/proximity"}),(0,i.jsx)(n.td,{children:"Line following, presence"}),(0,i.jsx)(n.td,{children:"cm to m"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Touch/Force"})}),(0,i.jsx)(n.td,{children:"Physical contact"}),(0,i.jsx)(n.td,{children:"Manipulation, safety"}),(0,i.jsx)(n.td,{children:"Direct contact"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Microphone"})}),(0,i.jsx)(n.td,{children:"Sound waves"}),(0,i.jsx)(n.td,{children:"Voice commands, localization"}),(0,i.jsx)(n.td,{children:"Room-scale"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"camera-systems",children:"Camera Systems"}),"\n",(0,i.jsx)(n.p,{children:"Cameras are the most versatile sensors, providing rich visual information:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'"""\nExample: Basic camera perception with OpenCV\nDemonstrates how robots "see" the world\n"""\n\nimport cv2\nimport numpy as np\n\ndef basic_camera_perception():\n    """\n    Capture and process a frame from a camera.\n    This is the foundation of visual perception.\n    """\n    # Initialize camera (0 = default webcam)\n    camera = cv2.VideoCapture(0)\n\n    # Capture a single frame\n    success, frame = camera.read()\n\n    if success:\n        # Convert to different color spaces for analysis\n        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n\n        # Basic image statistics (what the robot "perceives")\n        brightness = np.mean(gray)\n\n        print(f"Frame size: {frame.shape}")\n        print(f"Average brightness: {brightness:.2f}")\n\n        # Detect edges (finding object boundaries)\n        edges = cv2.Canny(gray, 50, 150)\n        edge_count = np.sum(edges > 0)\n        print(f"Edge pixels detected: {edge_count}")\n\n    camera.release()\n    return frame\n\n# Note: Run this only if you have a camera connected\n# frame = basic_camera_perception()\n'})}),"\n",(0,i.jsx)(n.h3,{id:"distance-sensors",children:"Distance Sensors"}),"\n",(0,i.jsx)(n.p,{children:"For spatial awareness, distance sensors are crucial:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'"""\nExample: Simulated distance sensor array\nShows how robots perceive obstacles around them\n"""\n\nimport math\nimport random\n\nclass DistanceSensorArray:\n    """\n    Simulates an array of ultrasonic sensors around a robot.\n    Real robots often have 4-8 sensors for 360\xb0 coverage.\n    """\n\n    def __init__(self, num_sensors=8, max_range=4.0):\n        self.num_sensors = num_sensors\n        self.max_range = max_range  # meters\n        # Angles for each sensor (evenly distributed)\n        self.angles = [i * (360 / num_sensors) for i in range(num_sensors)]\n\n    def read_all(self, obstacles):\n        """\n        Get readings from all sensors given obstacle positions.\n\n        Args:\n            obstacles: List of (x, y, radius) tuples\n\n        Returns:\n            Dictionary of sensor readings\n        """\n        readings = {}\n        for i, angle in enumerate(self.angles):\n            # Simulate ray casting to find nearest obstacle\n            distance = self._cast_ray(angle, obstacles)\n            readings[f"sensor_{i}"] = {\n                \'angle\': angle,\n                \'distance\': distance,\n                \'blocked\': distance < self.max_range\n            }\n        return readings\n\n    def _cast_ray(self, angle, obstacles):\n        """Simulate a single sensor ray."""\n        # Simplified: return random distance for simulation\n        # Real implementation would do actual ray-obstacle intersection\n        return random.uniform(0.5, self.max_range)\n\n    def get_danger_zones(self, readings, threshold=0.5):\n        """Identify which directions have close obstacles."""\n        dangers = []\n        for sensor_id, data in readings.items():\n            if data[\'distance\'] < threshold:\n                dangers.append(data[\'angle\'])\n        return dangers\n\n\n# Example usage\nsensors = DistanceSensorArray(num_sensors=8)\nobstacles = [(1.0, 0.5, 0.2), (0.3, -0.8, 0.1)]  # x, y, radius\nreadings = sensors.read_all(obstacles)\n\nprint("Sensor Readings:")\nfor sensor_id, data in readings.items():\n    status = "BLOCKED" if data[\'blocked\'] else "clear"\n    print(f"  {sensor_id}: {data[\'distance\']:.2f}m at {data[\'angle\']}\xb0 [{status}]")\n'})}),"\n",(0,i.jsx)(n.h3,{id:"sensor-fusion",children:"Sensor Fusion"}),"\n",(0,i.jsx)(n.p,{children:"Real systems combine multiple sensors for reliability:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"\"\"\"\nExample: Simple sensor fusion\nCombining multiple sensors for better estimates\n\"\"\"\n\nclass SensorFusion:\n    \"\"\"\n    Combines readings from multiple sensors to get\n    a more reliable estimate of the environment.\n    \"\"\"\n\n    def __init__(self):\n        self.weights = {\n            'camera': 0.4,\n            'lidar': 0.35,\n            'ultrasonic': 0.25\n        }\n\n    def fuse_distance_estimates(self, camera_dist, lidar_dist, ultrasonic_dist):\n        \"\"\"\n        Weighted average of distance estimates from multiple sensors.\n\n        In practice, more sophisticated methods like Kalman filters\n        are used, but this demonstrates the concept.\n        \"\"\"\n        fused = (\n            self.weights['camera'] * camera_dist +\n            self.weights['lidar'] * lidar_dist +\n            self.weights['ultrasonic'] * ultrasonic_dist\n        )\n\n        # Calculate confidence based on agreement\n        estimates = [camera_dist, lidar_dist, ultrasonic_dist]\n        variance = sum((e - fused)**2 for e in estimates) / len(estimates)\n        confidence = 1 / (1 + variance)  # Higher agreement = higher confidence\n\n        return {\n            'distance': fused,\n            'confidence': confidence,\n            'sources': {\n                'camera': camera_dist,\n                'lidar': lidar_dist,\n                'ultrasonic': ultrasonic_dist\n            }\n        }\n\n\n# Example\nfusion = SensorFusion()\nresult = fusion.fuse_distance_estimates(\n    camera_dist=2.3,\n    lidar_dist=2.1,\n    ultrasonic_dist=2.4\n)\nprint(f\"Fused distance: {result['distance']:.2f}m\")\nprint(f\"Confidence: {result['confidence']:.2%}\")\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"pillar-2-reasoning",children:"Pillar 2: Reasoning"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Reasoning"}),' is how a Physical AI system processes information and makes decisions. It answers: "What should I do?"']}),"\n",(0,i.jsx)(n.h3,{id:"levels-of-reasoning",children:"Levels of Reasoning"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   REASONING HIERARCHY                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                         \u2502\n\u2502  HIGH LEVEL    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  (Strategic)   \u2502  Mission Planning               \u2502     \u2502\n\u2502                \u2502  "Deliver package to Room 301"  \u2502     \u2502\n\u2502                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                              \u2502                          \u2502\n\u2502  MID LEVEL                   \u25bc                          \u2502\n\u2502  (Tactical)    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502                \u2502  Path Planning                  \u2502     \u2502\n\u2502                \u2502  "Navigate through hallway B"   \u2502     \u2502\n\u2502                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                              \u2502                          \u2502\n\u2502  LOW LEVEL                   \u25bc                          \u2502\n\u2502  (Reactive)    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502                \u2502  Behavior Control               \u2502     \u2502\n\u2502                \u2502  "Avoid obstacle on left"       \u2502     \u2502\n\u2502                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n'})}),"\n",(0,i.jsx)(n.h3,{id:"state-machine-implementation",children:"State Machine Implementation"}),"\n",(0,i.jsx)(n.p,{children:"State machines are fundamental to robot reasoning:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'"""\nExample: Finite State Machine for Robot Behavior\nA common pattern for implementing robot reasoning\n"""\n\nfrom enum import Enum, auto\n\nclass RobotState(Enum):\n    """Possible states for our robot."""\n    IDLE = auto()\n    SEARCHING = auto()\n    APPROACHING = auto()\n    GRABBING = auto()\n    RETURNING = auto()\n    ERROR = auto()\n\nclass RobotStateMachine:\n    """\n    A state machine controlling a simple fetch robot.\n\n    The robot:\n    1. Starts IDLE\n    2. SEARCHES for an object\n    3. APPROACHES the object when found\n    4. GRABS the object\n    5. RETURNS to home position\n    """\n\n    def __init__(self):\n        self.state = RobotState.IDLE\n        self.target_found = False\n        self.target_reached = False\n        self.object_grabbed = False\n        self.at_home = False\n\n    def update(self, sensor_data):\n        """\n        Main reasoning loop - called every cycle.\n\n        Args:\n            sensor_data: Dictionary with sensor readings\n        """\n        # State transition logic\n        if self.state == RobotState.IDLE:\n            self._handle_idle(sensor_data)\n\n        elif self.state == RobotState.SEARCHING:\n            self._handle_searching(sensor_data)\n\n        elif self.state == RobotState.APPROACHING:\n            self._handle_approaching(sensor_data)\n\n        elif self.state == RobotState.GRABBING:\n            self._handle_grabbing(sensor_data)\n\n        elif self.state == RobotState.RETURNING:\n            self._handle_returning(sensor_data)\n\n        return self.state\n\n    def _handle_idle(self, sensor_data):\n        """IDLE: Wait for command to start."""\n        if sensor_data.get(\'start_command\', False):\n            print("Starting search...")\n            self.state = RobotState.SEARCHING\n\n    def _handle_searching(self, sensor_data):\n        """SEARCHING: Look for target object."""\n        if sensor_data.get(\'target_visible\', False):\n            print("Target found! Approaching...")\n            self.target_found = True\n            self.state = RobotState.APPROACHING\n        # Continue searching behavior\n\n    def _handle_approaching(self, sensor_data):\n        """APPROACHING: Move toward target."""\n        distance = sensor_data.get(\'target_distance\', float(\'inf\'))\n        if distance < 0.1:  # Within grabbing range\n            print("Target reached! Grabbing...")\n            self.target_reached = True\n            self.state = RobotState.GRABBING\n        elif not sensor_data.get(\'target_visible\', True):\n            print("Lost target! Resuming search...")\n            self.state = RobotState.SEARCHING\n\n    def _handle_grabbing(self, sensor_data):\n        """GRABBING: Pick up the object."""\n        if sensor_data.get(\'gripper_closed\', False):\n            print("Object secured! Returning home...")\n            self.object_grabbed = True\n            self.state = RobotState.RETURNING\n\n    def _handle_returning(self, sensor_data):\n        """RETURNING: Go back to starting position."""\n        if sensor_data.get(\'at_home\', False):\n            print("Mission complete!")\n            self.at_home = True\n            self.state = RobotState.IDLE\n\n    def get_action(self):\n        """\n        Return the appropriate action for current state.\n        This connects reasoning to actuation.\n        """\n        actions = {\n            RobotState.IDLE: \'wait\',\n            RobotState.SEARCHING: \'rotate_and_scan\',\n            RobotState.APPROACHING: \'move_to_target\',\n            RobotState.GRABBING: \'close_gripper\',\n            RobotState.RETURNING: \'move_to_home\',\n            RobotState.ERROR: \'stop_and_alert\'\n        }\n        return actions.get(self.state, \'stop\')\n\n\n# Example simulation\nrobot = RobotStateMachine()\n\n# Simulate a mission\ntest_sequence = [\n    {\'start_command\': True},\n    {\'target_visible\': False},\n    {\'target_visible\': False},\n    {\'target_visible\': True, \'target_distance\': 2.0},\n    {\'target_visible\': True, \'target_distance\': 1.0},\n    {\'target_visible\': True, \'target_distance\': 0.05},\n    {\'gripper_closed\': True},\n    {\'at_home\': False},\n    {\'at_home\': True}\n]\n\nprint("=== Robot State Machine Demo ===\\n")\nfor i, sensor_data in enumerate(test_sequence):\n    state = robot.update(sensor_data)\n    action = robot.get_action()\n    print(f"Step {i}: State={state.name}, Action={action}")\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"pillar-3-actuation",children:"Pillar 3: Actuation"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Actuation"}),' is how a Physical AI system affects the physical world. It answers: "How do I do it?"']}),"\n",(0,i.jsx)(n.h3,{id:"common-actuator-types",children:"Common Actuator Types"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Actuator Type"}),(0,i.jsx)(n.th,{children:"Motion Type"}),(0,i.jsx)(n.th,{children:"Precision"}),(0,i.jsx)(n.th,{children:"Speed"}),(0,i.jsx)(n.th,{children:"Use Cases"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"DC Motor"})}),(0,i.jsx)(n.td,{children:"Continuous rotation"}),(0,i.jsx)(n.td,{children:"Low"}),(0,i.jsx)(n.td,{children:"High"}),(0,i.jsx)(n.td,{children:"Wheels, fans"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Servo Motor"})}),(0,i.jsx)(n.td,{children:"Angular position"}),(0,i.jsx)(n.td,{children:"High"}),(0,i.jsx)(n.td,{children:"Medium"}),(0,i.jsx)(n.td,{children:"Robot joints, steering"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Stepper Motor"})}),(0,i.jsx)(n.td,{children:"Discrete steps"}),(0,i.jsx)(n.td,{children:"Very High"}),(0,i.jsx)(n.td,{children:"Low"}),(0,i.jsx)(n.td,{children:"CNC, 3D printers"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Linear Actuator"})}),(0,i.jsx)(n.td,{children:"Straight line"}),(0,i.jsx)(n.td,{children:"Medium"}),(0,i.jsx)(n.td,{children:"Low"}),(0,i.jsx)(n.td,{children:"Lifts, doors"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Pneumatic"})}),(0,i.jsx)(n.td,{children:"Fast linear"}),(0,i.jsx)(n.td,{children:"Low"}),(0,i.jsx)(n.td,{children:"Very High"}),(0,i.jsx)(n.td,{children:"Grippers, presses"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"motor-control-example",children:"Motor Control Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'"""\nExample: Simulated motor control system\nDemonstrates how Physical AI systems control movement\n"""\n\nimport math\nimport time\n\nclass SimulatedMotor:\n    """\n    A simulated DC motor with basic physics.\n    Real motors have inertia, friction, and response delays.\n    """\n\n    def __init__(self, name, max_speed=100):\n        self.name = name\n        self.max_speed = max_speed  # RPM\n        self.current_speed = 0\n        self.target_speed = 0\n        self.acceleration = 50  # RPM per second\n\n    def set_speed(self, speed):\n        """Set target speed (will ramp to it)."""\n        self.target_speed = max(-self.max_speed, min(self.max_speed, speed))\n\n    def update(self, dt):\n        """\n        Update motor state based on time elapsed.\n\n        Args:\n            dt: Time delta in seconds\n        """\n        # Gradually change speed toward target (simulates inertia)\n        speed_diff = self.target_speed - self.current_speed\n        max_change = self.acceleration * dt\n\n        if abs(speed_diff) <= max_change:\n            self.current_speed = self.target_speed\n        else:\n            self.current_speed += math.copysign(max_change, speed_diff)\n\n    def get_status(self):\n        return {\n            \'name\': self.name,\n            \'current_speed\': self.current_speed,\n            \'target_speed\': self.target_speed,\n            \'at_target\': abs(self.current_speed - self.target_speed) < 0.1\n        }\n\n\nclass DifferentialDrive:\n    """\n    A differential drive robot with two motors.\n    Common in mobile robots for simple, effective steering.\n    """\n\n    def __init__(self, wheel_radius=0.05, wheel_base=0.2):\n        self.left_motor = SimulatedMotor("left")\n        self.right_motor = SimulatedMotor("right")\n        self.wheel_radius = wheel_radius  # meters\n        self.wheel_base = wheel_base  # meters between wheels\n\n        # Robot position and orientation\n        self.x = 0\n        self.y = 0\n        self.theta = 0  # radians\n\n    def set_velocity(self, linear, angular):\n        """\n        Set robot velocity using linear and angular components.\n\n        Args:\n            linear: Forward speed (m/s)\n            angular: Rotation speed (rad/s)\n        """\n        # Convert to individual wheel speeds\n        # v_left = linear - (angular * wheel_base / 2)\n        # v_right = linear + (angular * wheel_base / 2)\n\n        v_left = linear - (angular * self.wheel_base / 2)\n        v_right = linear + (angular * self.wheel_base / 2)\n\n        # Convert m/s to RPM\n        rpm_left = (v_left / (2 * math.pi * self.wheel_radius)) * 60\n        rpm_right = (v_right / (2 * math.pi * self.wheel_radius)) * 60\n\n        self.left_motor.set_speed(rpm_left)\n        self.right_motor.set_speed(rpm_right)\n\n    def update(self, dt):\n        """Update robot position based on motor speeds."""\n        self.left_motor.update(dt)\n        self.right_motor.update(dt)\n\n        # Convert RPM back to m/s\n        v_left = (self.left_motor.current_speed / 60) * 2 * math.pi * self.wheel_radius\n        v_right = (self.right_motor.current_speed / 60) * 2 * math.pi * self.wheel_radius\n\n        # Calculate robot velocity\n        linear = (v_left + v_right) / 2\n        angular = (v_right - v_left) / self.wheel_base\n\n        # Update position\n        self.x += linear * math.cos(self.theta) * dt\n        self.y += linear * math.sin(self.theta) * dt\n        self.theta += angular * dt\n\n    def get_pose(self):\n        return {\n            \'x\': self.x,\n            \'y\': self.y,\n            \'theta\': math.degrees(self.theta),\n            \'left_speed\': self.left_motor.current_speed,\n            \'right_speed\': self.right_motor.current_speed\n        }\n\n\n# Demo: Drive in a square\nrobot = DifferentialDrive()\nprint("=== Differential Drive Demo ===\\n")\n\n# Simulate driving\ncommands = [\n    ("Forward", 0.2, 0),      # Move forward\n    ("Turn left", 0, 0.5),    # Rotate\n    ("Forward", 0.2, 0),      # Move forward\n    ("Turn left", 0, 0.5),    # Rotate\n]\n\nfor name, linear, angular in commands:\n    print(f"Command: {name}")\n    robot.set_velocity(linear, angular)\n\n    # Simulate for 2 seconds\n    for _ in range(20):\n        robot.update(0.1)\n\n    pose = robot.get_pose()\n    print(f"  Position: ({pose[\'x\']:.2f}, {pose[\'y\']:.2f})")\n    print(f"  Heading: {pose[\'theta\']:.1f}\xb0")\n    print()\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"pillar-4-learning",children:"Pillar 4: Learning"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Learning"}),' is how a Physical AI system improves over time. It answers: "How can I do better?"']}),"\n",(0,i.jsx)(n.h3,{id:"types-of-learning-in-physical-ai",children:"Types of Learning in Physical AI"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Learning Type"}),(0,i.jsx)(n.th,{children:"How It Works"}),(0,i.jsx)(n.th,{children:"Example"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Supervised"})}),(0,i.jsx)(n.td,{children:"Learn from labeled examples"}),(0,i.jsx)(n.td,{children:"Object recognition training"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Reinforcement"})}),(0,i.jsx)(n.td,{children:"Learn from rewards/penalties"}),(0,i.jsx)(n.td,{children:"Robot navigation in maze"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Imitation"})}),(0,i.jsx)(n.td,{children:"Learn from demonstrations"}),(0,i.jsx)(n.td,{children:"Learning from human examples"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Self-Supervised"})}),(0,i.jsx)(n.td,{children:"Learn from unlabeled data"}),(0,i.jsx)(n.td,{children:"Predicting sensor readings"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"simple-learning-example",children:"Simple Learning Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'"""\nExample: Basic Q-Learning for a Simple Robot\nDemonstrates how robots can learn from experience\n"""\n\nimport random\nfrom collections import defaultdict\n\nclass SimpleLearningAgent:\n    """\n    A robot that learns to navigate using Q-learning.\n\n    Q-learning is a model-free reinforcement learning algorithm\n    that learns the value of actions in different states.\n    """\n\n    def __init__(self, actions, learning_rate=0.1, discount=0.9, epsilon=0.1):\n        self.actions = actions\n        self.learning_rate = learning_rate  # How fast to learn\n        self.discount = discount  # How much to value future rewards\n        self.epsilon = epsilon  # Exploration rate\n\n        # Q-table: maps (state, action) -> expected reward\n        self.q_table = defaultdict(float)\n\n        # Track learning progress\n        self.episode_rewards = []\n\n    def get_state_key(self, state):\n        """Convert state to hashable key."""\n        return tuple(state) if isinstance(state, list) else state\n\n    def choose_action(self, state):\n        """\n        Choose an action using epsilon-greedy policy.\n\n        With probability epsilon: explore (random action)\n        Otherwise: exploit (best known action)\n        """\n        state_key = self.get_state_key(state)\n\n        # Exploration: random action\n        if random.random() < self.epsilon:\n            return random.choice(self.actions)\n\n        # Exploitation: best known action\n        q_values = {a: self.q_table[(state_key, a)] for a in self.actions}\n        max_q = max(q_values.values())\n\n        # If multiple actions have same value, choose randomly among them\n        best_actions = [a for a, q in q_values.items() if q == max_q]\n        return random.choice(best_actions)\n\n    def learn(self, state, action, reward, next_state):\n        """\n        Update Q-value based on experience.\n\n        Q(s,a) = Q(s,a) + lr * (reward + discount * max(Q(s\',a\')) - Q(s,a))\n        """\n        state_key = self.get_state_key(state)\n        next_state_key = self.get_state_key(next_state)\n\n        # Current Q-value\n        current_q = self.q_table[(state_key, action)]\n\n        # Best Q-value for next state\n        next_q_values = [self.q_table[(next_state_key, a)] for a in self.actions]\n        max_next_q = max(next_q_values) if next_q_values else 0\n\n        # Update rule\n        new_q = current_q + self.learning_rate * (\n            reward + self.discount * max_next_q - current_q\n        )\n\n        self.q_table[(state_key, action)] = new_q\n\n    def get_learned_policy(self):\n        """Return the best action for each known state."""\n        states = set(key[0] for key in self.q_table.keys())\n        policy = {}\n        for state in states:\n            q_values = {a: self.q_table[(state, a)] for a in self.actions}\n            policy[state] = max(q_values, key=q_values.get)\n        return policy\n\n\n# Simple grid world for demonstration\nclass GridWorld:\n    """A simple grid environment for learning."""\n\n    def __init__(self, size=5):\n        self.size = size\n        self.goal = (size-1, size-1)\n        self.reset()\n\n    def reset(self):\n        self.position = (0, 0)\n        return self.position\n\n    def step(self, action):\n        """Take an action and return (new_state, reward, done)."""\n        x, y = self.position\n\n        if action == \'up\' and y > 0:\n            y -= 1\n        elif action == \'down\' and y < self.size - 1:\n            y += 1\n        elif action == \'left\' and x > 0:\n            x -= 1\n        elif action == \'right\' and x < self.size - 1:\n            x += 1\n\n        self.position = (x, y)\n\n        # Reward structure\n        if self.position == self.goal:\n            return self.position, 100, True  # Big reward for goal\n        else:\n            return self.position, -1, False  # Small penalty for each step\n\n\n# Train the agent\nprint("=== Q-Learning Demo ===\\n")\n\nenv = GridWorld(size=5)\nagent = SimpleLearningAgent(actions=[\'up\', \'down\', \'left\', \'right\'])\n\n# Training loop\nnum_episodes = 500\nfor episode in range(num_episodes):\n    state = env.reset()\n    total_reward = 0\n\n    for step in range(100):  # Max steps per episode\n        action = agent.choose_action(state)\n        next_state, reward, done = env.step(action)\n        agent.learn(state, action, reward, next_state)\n\n        total_reward += reward\n        state = next_state\n\n        if done:\n            break\n\n    if episode % 100 == 0:\n        print(f"Episode {episode}: Total Reward = {total_reward}")\n\nprint("\\nLearned Policy (best action per position):")\npolicy = agent.get_learned_policy()\nfor state in sorted(policy.keys()):\n    print(f"  Position {state}: {policy[state]}")\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"how-the-pillars-work-together",children:"How the Pillars Work Together"}),"\n",(0,i.jsx)(n.p,{children:"In a real Physical AI system, all four pillars operate simultaneously:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Time \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\n\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502Sense\u2502  \u2502Sense\u2502  \u2502Sense\u2502  \u2502Sense\u2502  \u2502Sense\u2502\n     \u2514\u2500\u2500\u252c\u2500\u2500\u2518  \u2514\u2500\u2500\u252c\u2500\u2500\u2518  \u2514\u2500\u2500\u252c\u2500\u2500\u2518  \u2514\u2500\u2500\u252c\u2500\u2500\u2518  \u2514\u2500\u2500\u252c\u2500\u2500\u2518\n        \u2502        \u2502        \u2502        \u2502        \u2502\n        \u25bc        \u25bc        \u25bc        \u25bc        \u25bc\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502Think\u2502  \u2502Think\u2502  \u2502Think\u2502  \u2502Think\u2502  \u2502Think\u2502\n     \u2514\u2500\u2500\u252c\u2500\u2500\u2518  \u2514\u2500\u2500\u252c\u2500\u2500\u2518  \u2514\u2500\u2500\u252c\u2500\u2500\u2518  \u2514\u2500\u2500\u252c\u2500\u2500\u2518  \u2514\u2500\u2500\u252c\u2500\u2500\u2518\n        \u2502        \u2502        \u2502        \u2502        \u2502\n        \u25bc        \u25bc        \u25bc        \u25bc        \u25bc\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502 Act \u2502  \u2502 Act \u2502  \u2502 Act \u2502  \u2502 Act \u2502  \u2502 Act \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2518\n\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n                   \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510\n                   \u2502  LEARN  \u2502 (Updates based on experience)\n                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Issue"}),(0,i.jsx)(n.th,{children:"Possible Cause"}),(0,i.jsx)(n.th,{children:"Solution"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Robot doesn't respond to sensors"}),(0,i.jsx)(n.td,{children:"Sensor not connected/initialized"}),(0,i.jsx)(n.td,{children:"Check wiring; verify initialization code"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Erratic movement"}),(0,i.jsx)(n.td,{children:"Sensor noise"}),(0,i.jsx)(n.td,{children:"Implement filtering; add sensor fusion"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Robot overshoots targets"}),(0,i.jsx)(n.td,{children:"No feedback control"}),(0,i.jsx)(n.td,{children:"Implement PID control"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Learning doesn't converge"}),(0,i.jsx)(n.td,{children:"Wrong hyperparameters"}),(0,i.jsx)(n.td,{children:"Adjust learning rate, exploration"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(n.h3,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\u2705 ",(0,i.jsx)(n.strong,{children:"Perception"})," gathers environmental data through sensors (cameras, LIDAR, IMU)"]}),"\n",(0,i.jsxs)(n.li,{children:["\u2705 ",(0,i.jsx)(n.strong,{children:"Reasoning"})," processes information and makes decisions (state machines, planners)"]}),"\n",(0,i.jsxs)(n.li,{children:["\u2705 ",(0,i.jsx)(n.strong,{children:"Actuation"})," executes physical actions through motors and actuators"]}),"\n",(0,i.jsxs)(n.li,{children:["\u2705 ",(0,i.jsx)(n.strong,{children:"Learning"})," improves performance over time through experience"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"checkpoint-quiz",children:"Checkpoint Quiz"}),"\n",(0,i.jsxs)("div",{className:"checkpoint-quiz",children:[(0,i.jsx)(n.p,{children:"Test your understanding:"}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"What is sensor fusion and why is it important?"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Name three types of motors and when you would use each one."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"What is the difference between reactive and deliberative reasoning?"}),"\n"]}),"\n"]}),(0,i.jsxs)(s,{children:[(0,i.jsx)("summary",{children:"View Answers"}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Sensor fusion"})," is combining data from multiple sensors to get more accurate or complete information. It's important because individual sensors have limitations (noise, blind spots, range), and combining them compensates for these weaknesses."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Motor types:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"DC Motor"}),": Continuous rotation, good for wheels and fans where precise position isn't needed"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Servo Motor"}),": Precise angular position control, good for robot joints and steering"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Stepper Motor"}),": Discrete steps with very high precision, good for 3D printers and CNC machines"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Reactive reasoning"})," responds directly to sensor input without planning (fast but simple). ",(0,i.jsx)(n.strong,{children:"Deliberative reasoning"})," plans ahead by considering future consequences (slower but handles complex scenarios). Most robots use a combination of both."]}),"\n"]}),"\n"]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,i.jsxs)(n.h3,{id:"basic-exercise-1-sensor-comparison",children:[(0,i.jsx)("span",{className:"exercise-badge exercise-badge--basic",children:"Basic"})," Exercise 1: Sensor Comparison"]}),"\n",(0,i.jsx)(n.p,{children:"Research and create a comparison table of 5 different sensors not covered in this lesson. Include: what they measure, typical applications, advantages, and limitations."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Expected Outcome:"})," A detailed table comparing sensors like force sensors, flex sensors, color sensors, etc."]}),"\n",(0,i.jsxs)(n.h3,{id:"intermediate-exercise-2-state-machine-design",children:[(0,i.jsx)("span",{className:"exercise-badge exercise-badge--intermediate",children:"Intermediate"})," Exercise 2: State Machine Design"]}),"\n",(0,i.jsx)(n.p,{children:"Design a state machine for a robot security guard that patrols, investigates disturbances, and alerts when threats are detected. Include at least 5 states and draw the transition diagram."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Expected Outcome:"})," A diagram and description of states, transitions, and triggering conditions."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\ud83d\udcc4 ",(0,i.jsx)(n.a,{href:"https://www.electronicshub.org/types-of-sensors/",children:"Introduction to Sensors in Robotics"})," - Overview of sensor technologies"]}),"\n",(0,i.jsxs)(n.li,{children:["\ud83d\udcc4 ",(0,i.jsx)(n.a,{href:"https://www.ni.com/en-us/innovations/white-papers/06/pid-theory-explained.html",children:"Understanding PID Control"})," - Deep dive into control systems"]}),"\n",(0,i.jsxs)(n.li,{children:["\ud83d\udcf9 ",(0,i.jsx)(n.a,{href:"https://www.youtube.com/playlist?list=PLqYmG7hTraZBiG_XpjnPrSNw-1XQaM_gB",children:"Reinforcement Learning Course"})," - DeepMind's RL series"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"whats-next",children:"What's Next?"}),"\n",(0,i.jsxs)(n.p,{children:["In the next lesson, ",(0,i.jsx)(n.a,{href:"/docs/01-foundations/lesson-03-your-first-physical-ai-system",children:"Your First Physical AI System"}),", you'll put all four pillars together and build a complete working system\u2014a simulated robot that perceives, reasons, acts, and learns."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.em,{children:"Estimated completion time: 60 minutes"})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453(e,n,s){s.d(n,{R:()=>a,x:()=>o});var t=s(6540);const i={},r=t.createContext(i);function a(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);